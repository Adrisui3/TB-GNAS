# Trajectory-based Graph Neural Architecture Search

Graph Neural Networks (GNN) have recently come to the forefront displaying superior performance on graph-structured data, and their potential has been exhibited in many real world applications. In spite of this, and similarly to other Deep Learning (DL) architectures, GNNs also come with a tedious but essential tuning work required to achieve decent performance on a given dataset. This process is heavily dependant on the specific scenario and requires domain expert knowledge. To overcome these dependencies, Neural Architecture Search (NAS) is the process of automatically finding the optimal neural architecture. In this work we propose a trajectory-based metaheuristic NAS method for GNNs, named Fuzzy Simulated Annealing NAS (FSA-NAS), which can find competitive solutions significantly faster than competitor approaches. Specifically, we design a novel probabilistic search space and tackle NAS as a bi-objective optimization problem. Additionally, we design a fuzzy rule based system to guide the search process. These two pieces are then combined with a variation of the well-known simulated annealing algorithm. Our experiments show that our method can find competitive results, similar to the current state-of-the-art in terms of performance, whilst achieving up to a 60x speedup even when running on low-end hardware.

For further details, please refer to the Documentation.pdf file included in this repository to find a full paper-like document including all the details and experiments conducted for this research.
